# -*- coding: utf-8 -*-
"""USM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G5h3CLeqYgqlmUszKtahGR7i18_X-Dea
"""

# @title
# -*- coding: utf-8 -*-
"""USM v1.2: Unified Science Machine

Hard Binding:
  - 4-object relational binding task
  - 2-layer CTM (fast+slow) with LTC, adaptive p, latent prediction loss
  - Supervised query→object binding loss (annealed)
  - Slot probes for color/shape/position
  - Object-permutation invariance for training & eval

GridWorld:
  - Minimal 5x5 GridWorld
  - USMGridWorldAgent with CTMBlock encoder
  - EternalHypergraph as experience memory
  - ActiveInferenceAgent selecting actions from memory-based Q

Single-file, Colab-friendly.
"""

import math
import random
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# ---------------------------------------------------------------------
# Config + device
# ---------------------------------------------------------------------

@dataclass
class USMConfig:
    world_type: str = "hard_binding"  # "hard_binding" or "gridworld"
    seed: int = 0
    device: str = "cuda"

    # Hard-binding specific
    hb_train_samples: int = 8000
    hb_eval_samples: int = 4000
    hb_epochs: int = 100
    hb_batch_size: int = 256
    hb_lr: float = 1e-3
    hb_pred_loss_weight: float = 0.2
    hb_permute_objects: bool = True
    hb_bind_loss_weight: float = 1.0
    hb_bind_loss_warmup_epochs: int = 20
    hb_bind_loss_max_epochs: int = 80
    hb_probe_loss_weight: float = 0.1

    # GridWorld specific
    gw_size: int = 5
    gw_n_episodes: int = 200
    gw_max_steps: int = 40
    gw_lr: float = 1e-3
    gw_gamma: float = 0.99
    gw_latent_dim: int = 64


def resolve_device(cfg: USMConfig) -> torch.device:
    if cfg.device == "cuda" and torch.cuda.is_available():
        return torch.device("cuda")
    return torch.device("cpu")


# default device (updated in main)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ---------------------------------------------------------------------
# HARD BINDING DATASET (with candidate mask + optional object permutation)
# ---------------------------------------------------------------------

class HardBindingDataset(Dataset):
    """
    Scene with 4 objects, each has:
      - color ∈ {red, green, blue, yellow}
      - shape ∈ {ball, cube, cone, star}
      - (x, y) ∈ {0,0.2,0.4,0.6,0.8}²

    Query:
      "What shape is <target_color> <relation> of <ref_color>?"

    Relations:
      - left_of, right_of, above, below

    Label:
      - shape index of one candidate object satisfying the relation.
      - Some scenes are ambiguous (multiple candidates) → marked separately.

    Extra (for binding probes / supervision):
      - cand_mask: [4] bool, which object indices satisfy the relation.

    Encoding:
      - 4 objects × (color one-hot 4 + shape one-hot 4 + x + y) = 4 × 10 = 40
      - query = target_color (4) + relation (4) + ref_color (4) = 12
      - total input dim = 52

    permute_objects=True:
      - At __getitem__ time, randomly permutes the 4 objects and cand_mask
        to enforce permutation invariance and avoid slot-index cheating.
    """
    COLORS = ["red", "green", "blue", "yellow"]
    SHAPES = ["ball", "cube", "cone", "star"]
    RELS = ["left_of", "right_of", "above", "below"]

    def __init__(self, n_samples: int = 8000, seed: int = 0,
                 permute_objects: bool = False):
        self.n_samples = n_samples
        self.permute_objects = permute_objects
        self.rng = random.Random(seed)
        # Each sample: (x, y, ambiguous, cand_mask, objects, query)
        self.samples: List[Tuple[torch.Tensor, int, bool, torch.Tensor, list, tuple]] = []
        self._generate()

    def _sample_coord(self) -> float:
        # 5×5 grid → coordinates in {0,0.2,0.4,0.6,0.8}
        return self.rng.choice([0.0, 0.2, 0.4, 0.6, 0.8])

    def _relation_holds(self, obj, ref, rel: str) -> bool:
        x, y = obj["x"], obj["y"]
        rx, ry = ref["x"], ref["y"]
        if rel == "left_of":
            return x < rx and abs(y - ry) <= 0.4
        if rel == "right_of":
            return x > rx and abs(y - ry) <= 0.4
        if rel == "above":
            return y > ry and abs(x - rx) <= 0.4
        if rel == "below":
            return y < ry and abs(x - rx) <= 0.4
        return False

    def _generate_one(self):
        colors = self.COLORS
        shapes = self.SHAPES
        rels = self.RELS

        # 4 random objects
        objects = []
        for _ in range(4):
            obj = {
                "color": self.rng.choice(colors),
                "shape": self.rng.choice(shapes),
                "x": self._sample_coord(),
                "y": self._sample_coord(),
            }
            objects.append(obj)

        # Query + label
        attempts = 0
        while True:
            attempts += 1
            ref_idx = self.rng.randrange(4)
            ref = objects[ref_idx]
            ref_color = ref["color"]

            target_color = self.rng.choice(colors)
            rel = self.rng.choice(rels)

            # Candidate targets: objects of target_color in relation
            # to any object of ref_color
            candidates = []
            for i, obj in enumerate(objects):
                if obj["color"] != target_color:
                    continue
                holds_any = False
                for j, ref2 in enumerate(objects):
                    if ref2["color"] == ref_color and i != j:
                        if self._relation_holds(obj, ref2, rel):
                            holds_any = True
                            break
                if holds_any:
                    candidates.append(i)

            if candidates:
                break
            if attempts > 20:
                # Fallback: no candidate, treat as non-ambiguous random label
                candidates = [self.rng.randrange(4)]
                break

        ambiguous = len(candidates) > 1
        chosen_idx = self.rng.choice(candidates)
        answer_shape = objects[chosen_idx]["shape"]
        y = shapes.index(answer_shape)

        # Candidate mask [4] for binding probes / supervision
        cand_mask = torch.zeros(4, dtype=torch.bool)
        for idx in candidates:
            cand_mask[idx] = True

        # Encode features
        feat = []
        for obj in objects:
            color_oh = [1.0 if obj["color"] == c else 0.0 for c in colors]
            shape_oh = [1.0 if obj["shape"] == s else 0.0 for s in shapes]
            feat.extend(color_oh + shape_oh + [obj["x"], obj["y"]])

        tgt_oh = [1.0 if target_color == c else 0.0 for c in colors]
        rel_oh = [1.0 if rel == r else 0.0 for r in rels]
        ref_oh = [1.0 if ref_color == c else 0.0 for c in colors]
        feat.extend(tgt_oh + rel_oh + ref_oh)

        x = torch.tensor(feat, dtype=torch.float32)
        query = (target_color, rel, ref_color)
        return x, y, ambiguous, cand_mask, objects, query

    def _generate(self):
        self.samples = [self._generate_one() for _ in range(self.n_samples)]

    def __len__(self):
        return self.n_samples

    def __getitem__(self, idx):
        x, y, amb, cand_mask, objects, query = self.samples[idx]
        x = x.clone()
        cand_mask = cand_mask.clone()

        obj_colors_idx = torch.tensor(
            [self.COLORS.index(obj["color"]) for obj in objects], dtype=torch.long
        )
        obj_shapes_idx = torch.tensor(
            [self.SHAPES.index(obj["shape"]) for obj in objects], dtype=torch.long
        )
        obj_pos = torch.tensor(
            [[obj["x"], obj["y"]] for obj in objects], dtype=torch.float32
        )

        if self.permute_objects:
            obj_feats = x[:40].view(4, 10)
            perm = torch.randperm(4)
            obj_feats = obj_feats[perm]
            x[:40] = obj_feats.view(-1)
            cand_mask = cand_mask[perm]
            obj_colors_idx = obj_colors_idx[perm]
            obj_shapes_idx = obj_shapes_idx[perm]
            obj_pos = obj_pos[perm]

        return x, y, amb, cand_mask, obj_colors_idx, obj_shapes_idx, obj_pos

    def sample_humans(self, k: int = 3):
        """Return a few human-readable examples for logging."""
        out = []
        for i in range(min(k, len(self.samples))):
            x, y, amb, cand_mask, objects, query = self.samples[i]
            out.append((objects, query, self.SHAPES[y], amb))
        return out


def ambig_fraction(ds: HardBindingDataset):
    ambigs = sum(1 for _, _, amb, _, _, _ in ds.samples if amb)
    return ambigs / len(ds.samples), ambigs


# ---------------------------------------------------------------------
# MODELS: MLP baseline
# ---------------------------------------------------------------------

class MLPBaseline(nn.Module):
    def __init__(self, input_dim=52, hidden=64, n_classes=4):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, n_classes),
        )

    def forward(self, x):
        return self.net(x)


# ---------------------------------------------------------------------
# CTM block: LTC + adaptive p + latent prediction
# ---------------------------------------------------------------------

class CTMBlock(nn.Module):
    def __init__(self, dim, n_slots, n_ticks=3, dt=1.0,
                 p_min=2.0, p_max=4.0):
        super().__init__()
        self.dim = dim
        self.n_slots = n_slots
        self.n_ticks = n_ticks
        self.dt = dt
        self.p_min = p_min
        self.p_max = p_max

        self.in_proj = nn.Linear(dim, dim)
        self.pre_ln = nn.LayerNorm(dim)

        self.q_proj = nn.Linear(dim, dim)
        self.k_proj = nn.Linear(dim, dim)
        self.v_proj = nn.Linear(dim, dim)
        self.out_proj = nn.Linear(dim, dim)

        # LTC per-dimension timescales
        self.log_tau = nn.Parameter(torch.zeros(dim))

        # Latent prediction network: predict z_{t+1} from z_t
        self.pred_net = nn.Sequential(
            nn.Linear(dim, dim),
            nn.ReLU(),
            nn.Linear(dim, dim),
        )

    def forward(self, z, return_attn: bool = False):
        """
        z: [B, T, d]

        Returns:
          z_new: [B, T, d]
          pred_loss: scalar
          eff_p_mean: scalar (detached, for logging)
          last_attn: [B, T, T] or None (final tick attention)
        """
        B, T, d = z.shape
        tau = torch.exp(self.log_tau).view(1, 1, d)  # [1,1,d]

        pred_losses = []
        eff_ps = []
        last_attn = None

        for _ in range(self.n_ticks):
            h = self.pre_ln(self.in_proj(z))  # [B,T,d]

            Q = self.q_proj(h)
            K = self.k_proj(h)
            V = self.v_proj(h)

            sim = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d)  # [B,T,T]
            attn = torch.softmax(sim, dim=-1)  # [B,T,T]

            # Attention peakiness → sync confidence
            row_max = attn.max(dim=-1).values  # [B,T]
            uniform = 1.0 / T
            conf = (row_max.mean(dim=-1) - uniform) / (1.0 - uniform + 1e-6)
            conf = conf.clamp(0.0, 1.0)  # [B]

            eff_p = self.p_min + (self.p_max - self.p_min) * conf
            eff_ps.append(eff_p.detach())

            eff_p_exp = eff_p.view(B, 1, 1)
            sim_sharp = sim * eff_p_exp
            attn_sharp = torch.softmax(sim_sharp, dim=-1)
            last_attn = attn_sharp  # last tick attention

            context = torch.matmul(attn_sharp, V)  # [B,T,d]
            target = self.out_proj(context)        # [B,T,d]

            # Latent prediction z_pred ≈ z_next
            z_pred = self.pred_net(z)

            dz = (target - z) / (tau + 1e-6)
            z_next = z + self.dt * dz

            pred_loss = F.mse_loss(z_pred, z_next.detach())
            pred_losses.append(pred_loss)

            z = z_next

        pred_loss_mean = torch.stack(pred_losses).mean()
        eff_p_mean = torch.cat(eff_ps).mean()
        if return_attn:
            return z, pred_loss_mean, eff_p_mean.detach(), last_attn
        else:
            return z, pred_loss_mean, eff_p_mean.detach(), None


# ---------------------------------------------------------------------
# Hierarchical CTM model: 2 layers (fast + slow)
# ---------------------------------------------------------------------

class CTMHierModel(nn.Module):
    """
    2-layer CTM-ish model for hard binding:

    - Encodes 4 objects into slots.
    - Encodes query into a separate slot.
    - Total slots: 5 (4 objects + 1 query).
    - Layer 1: fast CTM (few ticks).
    - Layer 2: slow CTM (more ticks).
    - Reads out from query slot after slow layer.
    """

    def __init__(self, input_dim=52, slot_dim=32, n_slots=4, n_classes=4,
                 n_ticks_fast=2, n_ticks_slow=3):
        super().__init__()
        self.input_dim = input_dim
        self.slot_dim = slot_dim
        self.n_slots = n_slots
        self.n_classes = n_classes

        # Each object chunk: color(4) + shape(4) + x + y = 10 dims
        self.obj_dim = 10
        assert 4 * self.obj_dim + 12 == input_dim, "input_dim mismatch"

        # Object encoder: 10 -> slot_dim
        self.slot_enc = nn.Sequential(
            nn.Linear(self.obj_dim, slot_dim),
            nn.ReLU(),
            nn.Linear(slot_dim, slot_dim),
        )

        # Query encoder: 12 -> slot_dim
        self.query_enc = nn.Sequential(
            nn.Linear(12, slot_dim),
            nn.ReLU(),
            nn.Linear(slot_dim, slot_dim),
        )

        # Hierarchical CTM blocks
        self.ctm_fast = CTMBlock(slot_dim, n_slots + 1, n_ticks=n_ticks_fast)
        self.ctm_slow = CTMBlock(slot_dim, n_slots + 1, n_ticks=n_ticks_slow)

        # Per-slot shape head (object-wise logits)
        self.slot_shape_head = nn.Linear(slot_dim, n_classes)

        # Diagnostic probe heads
        self.probe_color = nn.Linear(self.slot_dim, 4)
        self.probe_shape = nn.Linear(self.slot_dim, 4)
        self.probe_pos = nn.Linear(self.slot_dim, 2)

    def encode_slots(self, x):
        """
        x: [B, 52]
        Returns:
          z0: [B, 5, slot_dim]
          slots 0..3: objects
          slot 4: query
        """
        B = x.shape[0]
        obj_feats = x[:, :4 * self.obj_dim].view(B, 4, self.obj_dim)  # [B,4,10]
        query_feats = x[:, 4 * self.obj_dim:]                          # [B,12]

        obj_emb = self.slot_enc(obj_feats)                             # [B,4,D]
        query_emb = self.query_enc(query_feats).unsqueeze(1)           # [B,1,D]

        z0 = torch.cat([obj_emb, query_emb], dim=1)                    # [B,5,D]
        return z0

    def forward(self, x, return_attn: bool = False, return_slots: bool = False):
        """
        x: [B, 52]
        Returns:
          logits: [B, n_classes]
          pred_loss: scalar
          eff_p_mean: scalar
          attn_q2s: [B, n_slots] or None (query→object attention)
        """
        z = self.encode_slots(x)
        z, pred_loss_fast, eff_p_fast, _ = self.ctm_fast(z, return_attn=False)
        z, pred_loss_slow, eff_p_slow, attn_last = self.ctm_slow(z, return_attn=True)

        pred_loss = pred_loss_fast + pred_loss_slow
        eff_p_mean = 0.5 * (eff_p_fast + eff_p_slow)
        slots = z[:, :self.n_slots, :]  # [B, n_slots, D]

        # Query→slot attention (query row to object columns)
        if attn_last is not None:
            q_idx = attn_last.shape[1] - 1
            obj_attn = attn_last[:, q_idx, :self.n_slots]  # [B, n_slots]
            attn_q2s = obj_attn / (obj_attn.sum(dim=-1, keepdim=True) + 1e-8)
        else:
            attn_q2s = None

        # Per-slot logits
        slot_logits = self.slot_shape_head(slots)  # [B, n_slots, n_classes]

        # Pointer-style aggregation (log-space mix)
        log_p_slots = F.log_softmax(slot_logits, dim=-1)
        if attn_q2s is None:
            attn_q2s = torch.full(
                (slots.size(0), self.n_slots),
                1.0 / self.n_slots,
                device=slots.device,
            )
        log_attn = torch.log(attn_q2s.clamp_min(1e-8)).unsqueeze(-1)
        joint_log = log_p_slots + log_attn
        final_logits = torch.logsumexp(joint_log, dim=1)  # [B, n_classes]

        if not return_attn:
            attn_q2s = None

        if return_slots:
            return final_logits, pred_loss, eff_p_mean, attn_q2s, slots

        return final_logits, pred_loss, eff_p_mean, attn_q2s


# ---------------------------------------------------------------------
# Classification evaluation
# ---------------------------------------------------------------------

def evaluate_model(model, loader, device):
    model.eval()
    correct = total = 0
    correct_simple = total_simple = 0
    correct_amb = total_amb = 0

    with torch.no_grad():
        for x, y, amb, cand_mask, _, _, _ in loader:
            x = x.to(device)
            y = y.to(device)

            if isinstance(model, CTMHierModel):
                logits, _, _, _ = model(x)
            else:
                logits = model(x)

            preds = logits.argmax(dim=-1)

            correct += (preds == y).sum().item()
            total += y.numel()

            amb = amb.to(torch.bool)
            simple_mask = ~amb
            amb_mask = amb

            simple_idx = simple_mask.nonzero(as_tuple=False).squeeze(-1)
            amb_idx = amb_mask.nonzero(as_tuple=False).squeeze(-1)

            if simple_idx.numel() > 0:
                correct_simple += (preds[simple_idx] == y[simple_idx]).sum().item()
                total_simple += simple_idx.numel()

            if amb_idx.numel() > 0:
                correct_amb += (preds[amb_idx] == y[amb_idx]).sum().item()
                total_amb += amb_idx.numel()

    overall = correct / total if total else 0.0
    simple = correct_simple / total_simple if total_simple else 0.0
    amb = correct_amb / total_amb if total_amb else 0.0
    return overall, simple, amb


# ---------------------------------------------------------------------
# Binding evaluation (query-slot attention → object slots)
# ---------------------------------------------------------------------

def evaluate_binding(ctm: CTMHierModel, loader, device, n_obj_slots: int = 4):
    """
    Probes whether the query slot's attention actually binds to the correct objects.

    For each sample:
      - Take attention from query slot row to the first n_obj_slots.
      - Binding-argmax is index of max attention among object slots.
      - If that index is in cand_mask (a valid candidate), count as success.
    """
    ctm.eval()
    correct = total = 0
    correct_simple = total_simple = 0
    correct_amb = total_amb = 0
    mass_sum = 0.0
    mass_count = 0

    with torch.no_grad():
        for x, y, amb, cand_mask, _, _, _ in loader:
            x = x.to(device)
            amb = amb.to(torch.bool)
            cand_mask = cand_mask.to(device)  # [B,4]

            logits, _, _, attn_q2s = ctm(x, return_attn=True)
            if attn_q2s is None:
                continue

            obj_attn = attn_q2s[:, :n_obj_slots]  # [B,4]
            B = obj_attn.shape[0]

            max_idx = obj_attn.argmax(dim=-1)  # [B]
            batch_indices = torch.arange(B, device=device)
            correct_flags = cand_mask[batch_indices, max_idx]  # bool

            correct += correct_flags.sum().item()
            total += B

            mass_on_correct = (obj_attn * cand_mask.float()).sum(dim=-1)  # [B]
            mass_sum += mass_on_correct.sum().item()
            mass_count += B

            simple_mask = ~amb
            amb_mask = amb

            if simple_mask.any():
                sm_idx = simple_mask.nonzero(as_tuple=False).squeeze(-1)
                correct_simple += correct_flags[sm_idx].sum().item()
                total_simple += sm_idx.numel()

            if amb_mask.any():
                am_idx = amb_mask.nonzero(as_tuple=False).squeeze(-1)
                correct_amb += correct_flags[am_idx].sum().item()
                total_amb += am_idx.numel()

    overall = correct / total if total else 0.0
    simple = correct_simple / total_simple if total_simple else 0.0
    amb = correct_amb / total_amb if total_amb else 0.0
    mean_mass = mass_sum / mass_count if mass_count else 0.0
    return overall, simple, amb, mean_mass


# ---------------------------------------------------------------------
# Supervised binding loss
# ---------------------------------------------------------------------

def compute_binding_loss(attn_q2s: torch.Tensor,
                         cand_mask: torch.Tensor,
                         amb: torch.Tensor,
                         eps: float = 1e-8) -> torch.Tensor:
    """
    Supervised binding loss for query→object attention.

    - Simple scenes: cross-entropy to the single correct slot.
    - Ambiguous scenes: soft target over all valid candidates.
    """
    if attn_q2s is None:
        # No attention (should not happen when return_attn=True)
        return torch.tensor(0.0, device=cand_mask.device)

    cand_mask = cand_mask.to(attn_q2s.device)
    amb = amb.to(attn_q2s.device).bool()

    simple_mask = ~amb
    loss_terms = []

    # Simple: single candidate → NLL
    if simple_mask.any():
        idx = simple_mask.nonzero(as_tuple=False).squeeze(-1)
        attn_simple = attn_q2s[idx]           # [B_simple, n_slots]
        cand_simple = cand_mask[idx].float()  # [B_simple, n_slots]
        target_idx = cand_simple.argmax(dim=-1)
        log_attn = (attn_simple + eps).log()
        ce_simple = F.nll_loss(log_attn, target_idx, reduction="mean")
        loss_terms.append(ce_simple)

    # Ambiguous: multiple candidates → soft cross-entropy
    if amb.any():
        idx = amb.nonzero(as_tuple=False).squeeze(-1)
        attn_amb = attn_q2s[idx]
        cand_amb = cand_mask[idx].float()
        cand_sum = cand_amb.sum(dim=-1, keepdim=True)  # [B_amb,1]
        valid = cand_sum.squeeze(-1) > 0
        if valid.any():
            attn_amb = attn_amb[valid]
            cand_amb = cand_amb[valid]
            cand_soft = cand_amb / (cand_sum[valid] + eps)
            log_attn = (attn_amb + eps).log()
            ce_amb = -(cand_soft * log_attn).sum(dim=-1).mean()
            loss_terms.append(ce_amb)

    if not loss_terms:
        return torch.tensor(0.0, device=attn_q2s.device)

    return torch.stack(loss_terms).mean()


def binding_weight_for_epoch(epoch: int, warmup: int, max_ep: int, max_w: float) -> float:
    if epoch < warmup:
        return 0.0
    if epoch >= max_ep:
        return max_w
    alpha = (epoch - warmup) / max(1, max_ep - warmup)
    return float(alpha * max_w)


# ---------------------------------------------------------------------
# HARD BINDING EXPERIMENT
# ---------------------------------------------------------------------

def run_hard_binding_experiment(cfg: USMConfig):
    global device
    device = resolve_device(cfg)
    torch.manual_seed(cfg.seed)
    random.seed(cfg.seed)

    print("=" * 60)
    print(
        "USM v1.2: HARD BINDING + 2-LAYER CTM + ADAPTIVE p + LATENT PRED"
        " + BINDING LOSS (ANNEALED) + PROBES + PERM-INVARIANT"
    )
    print("=" * 60)
    print("Device:", device)

    # Datasets
    train_ds = HardBindingDataset(
        n_samples=cfg.hb_train_samples,
        seed=cfg.seed,
        permute_objects=cfg.hb_permute_objects,
    )
    eval_ds = HardBindingDataset(
        n_samples=cfg.hb_eval_samples,
        seed=cfg.seed + 1,
        permute_objects=cfg.hb_permute_objects,
    )

    amb_train, amb_train_n = ambig_fraction(train_ds)
    amb_eval, amb_eval_n = ambig_fraction(eval_ds)

    print("\nHard Binding Task:")
    print(f"  Objects: 4")
    print(f"  Colors can REPEAT: True")
    print(f"  Input dim: 52")
    print(f"  Output dim: 4 (shapes)")
    print(f"  Ambiguous fraction (train): {amb_train*100:.1f}% ({amb_train_n} cases)")
    print(f"  Ambiguous fraction (eval):  {amb_eval*100:.1f}% ({amb_eval_n} cases)")

    print("\n--- Examples ---\n")
    for objects, query, answer, amb in train_ds.sample_humans(3):
        qs = f"What shape is {query[0]} {query[1]} of {query[2]}?"
        print(f"Objects: {[(o['color'], o['shape'], o['x'], o['y']) for o in objects]}")
        print(f"Query: {qs}")
        print(f"Answer: {answer}")
        print(f"Has ambiguity: {amb}\n")

    train_loader = DataLoader(train_ds, batch_size=cfg.hb_batch_size, shuffle=True)
    eval_loader = DataLoader(eval_ds, batch_size=cfg.hb_batch_size, shuffle=False)

    # Models
    mlp = MLPBaseline(input_dim=52, hidden=64, n_classes=4).to(device)
    ctm = CTMHierModel(input_dim=52, slot_dim=32, n_slots=4, n_classes=4,
                       n_ticks_fast=2, n_ticks_slow=3).to(device)

    n_params_ctm = sum(p.numel() for p in ctm.parameters())
    n_params_mlp = sum(p.numel() for p in mlp.parameters())
    print("----------------------------------------")
    print("MODELS")
    print("----------------------------------------")
    print(f"CTM: {n_params_ctm:,} params")
    print(f"MLP: {n_params_mlp:,} params")
    print(f"Ratio: {n_params_ctm / max(1, n_params_mlp):.2f}x")

    # Train MLP baseline
    print("\n----------------------------------------")
    print(f"TRAINING MLP ({cfg.hb_epochs} epochs)")
    print("----------------------------------------")
    ce = nn.CrossEntropyLoss()
    opt_mlp = torch.optim.AdamW(mlp.parameters(), lr=cfg.hb_lr)

    for epoch in range(1, cfg.hb_epochs + 1):
        mlp.train()
        for x, y, amb, cand_mask, _, _, _ in train_loader:
            x = x.to(device)
            y = y.to(device)
            opt_mlp.zero_grad()
            logits = mlp(x)
            loss = ce(logits, y)
            loss.backward()
            opt_mlp.step()

        if epoch % 20 == 0 or epoch == cfg.hb_epochs:
            acc, acc_simple, acc_amb = evaluate_model(mlp, eval_loader, device)
            print(f"Epoch {epoch:3d} | MLP | "
                  f"Eval: {acc*100:4.1f}% | "
                  f"Simple: {acc_simple*100:4.1f}% | "
                  f"Ambig: {acc_amb*100:4.1f}%")

    # Train CTM (classification + latent pred + binding supervision)
    print("\n----------------------------------------")
    print(f"TRAINING CTM ({cfg.hb_epochs} epochs)"
          " + Adaptive p + Latent Pred Loss + Binding Loss")
    print("----------------------------------------")

    opt_ctm = torch.optim.AdamW(ctm.parameters(), lr=cfg.hb_lr)
    pred_loss_weight = cfg.hb_pred_loss_weight
    bind_loss_weight_max = cfg.hb_bind_loss_weight
    bind_warmup = cfg.hb_bind_loss_warmup_epochs
    bind_max_ep = cfg.hb_bind_loss_max_epochs

    for epoch in range(1, cfg.hb_epochs + 1):
        ctm.train()
        running_eff_p = 0.0
        running_batches = 0
        last_pred_loss_val = 0.0
        last_bind_loss_val = 0.0
        last_probe_loss_val = 0.0
        attn_debug_stats = None
        bind_w = binding_weight_for_epoch(epoch, bind_warmup, bind_max_ep, bind_loss_weight_max)

        for x, y, amb, cand_mask, obj_colors, obj_shapes, obj_pos in train_loader:
            x = x.to(device)
            y = y.to(device)
            amb = amb.to(device)
            cand_mask = cand_mask.to(device)
            obj_colors = obj_colors.to(device)
            obj_shapes = obj_shapes.to(device)
            obj_pos = obj_pos.to(device)

            # Always request attention; we need it for binding loss
            opt_ctm.zero_grad()
            logits, pred_loss, eff_p_mean, attn_q2s, slots = ctm(
                x, return_attn=True, return_slots=True
            )

            loss_cls = ce(logits, y)
            bind_loss = compute_binding_loss(attn_q2s, cand_mask, amb)

            B, N, D = slots.shape
            slots_flat = slots.reshape(B * N, D)
            colors_flat = obj_colors.view(B * N)
            shapes_flat = obj_shapes.view(B * N)
            pos_flat = obj_pos.view(B * N, 2)

            color_logits = ctm.probe_color(slots_flat)
            shape_logits = ctm.probe_shape(slots_flat)
            pos_pred = ctm.probe_pos(slots_flat)

            loss_color = F.cross_entropy(color_logits, colors_flat)
            loss_shape = F.cross_entropy(shape_logits, shapes_flat)
            loss_pos = F.mse_loss(pos_pred, pos_flat)
            probe_loss = loss_color + loss_shape + loss_pos

            loss = (
                loss_cls
                + pred_loss_weight * pred_loss
                + bind_w * bind_loss
                + cfg.hb_probe_loss_weight * probe_loss
            )
            loss.backward()
            opt_ctm.step()

            running_eff_p += float(eff_p_mean)
            running_batches += 1
            last_pred_loss_val = pred_loss.detach().item()
            last_bind_loss_val = bind_loss.detach().item()
            last_probe_loss_val = probe_loss.detach().item()

            if attn_debug_stats is None and attn_q2s is not None:
                with torch.no_grad():
                    attn_sum = attn_q2s.sum(dim=-1)
                    attn_debug_stats = (
                        float(attn_q2s.min()),
                        float(attn_q2s.max()),
                        float(attn_sum.mean()),
                        bool(attn_q2s.requires_grad),
                    )

        if epoch % 20 == 0 or epoch == cfg.hb_epochs:
            acc, acc_simple, acc_amb = evaluate_model(ctm, eval_loader, device)
            avg_eff_p = running_eff_p / max(1, running_batches)
            if attn_debug_stats is not None:
                attn_min, attn_max, attn_sum_mean, attn_req_grad = attn_debug_stats
                print(f"  [AttnDbg] min={attn_min:.4f} max={attn_max:.4f} "
                      f"mean_sum={attn_sum_mean:.4f} requires_grad={attn_req_grad}")
            print(f"Epoch {epoch:3d} | CTM | "
                  f"Eval: {acc*100:4.1f}% | "
                  f"Simple: {acc_simple*100:4.1f}% | "
                  f"Ambig: {acc_amb*100:4.1f}% | "
                  f"PredLoss: {last_pred_loss_val:.4f} | "
                  f"BindLoss: {last_bind_loss_val:.4f} | "
                  f"ProbeLoss: {last_probe_loss_val:.4f} | "
                  f"BindW: {bind_w:.3f} | "
                  f"eff_p: {avg_eff_p:.2f}")

    # Final classification comparison
    print("\n" + "=" * 60)
    print("DETAILED EVALUATION (CLASSIFICATION)")
    print("=" * 60)

    mlp_overall, mlp_simple, mlp_amb = evaluate_model(mlp, eval_loader, device)
    ctm_overall, ctm_simple, ctm_amb = evaluate_model(ctm, eval_loader, device)

    print("\nMLP Results:")
    print(f"  Overall: {mlp_overall*100:4.1f}%")
    print(f"  Simple (no ambiguity): {mlp_simple*100:4.1f}%")
    print(f"  AMBIGUOUS (hard): {mlp_amb*100:4.1f}%")

    print("\nCTM Results:")
    print(f"  Overall: {ctm_overall*100:4.1f}%")
    print(f"  Simple (no ambiguity): {ctm_simple*100:4.1f}%")
    print(f"  AMBIGUOUS (hard): {ctm_amb*100:4.1f}%")

    print("\n" + "=" * 60)
    print("CLASSIFICATION COMPARISON")
    print("=" * 60)
    print("\nOVERALL:")
    print(f"  MLP: {mlp_overall*100:4.1f}%")
    print(f"  CTM: {ctm_overall*100:4.1f}%")
    print(f"  Diff: {(ctm_overall-mlp_overall)*100:4.1f}%")

    print("\nAMBIGUOUS CASES (TRUE BINDING TEST, via answers only):")
    print(f"  MLP: {mlp_amb*100:4.1f}%")
    print(f"  CTM: {ctm_amb*100:4.1f}%")
    print(f"  Diff: {(ctm_amb-mlp_amb)*100:4.1f}%")

    # Binding probes
    print("\n" + "=" * 60)
    print("BINDING PROBES (QUERY ATTENTION → OBJECT SLOTS)")
    print("=" * 60)

    bind_overall, bind_simple, bind_amb, mass_mean = evaluate_binding(
        ctm, eval_loader, device, n_obj_slots=4
    )
    print(f"\nBinding argmax accuracy (query attention to correct object):")
    print(f"  Overall: {bind_overall*100:4.1f}%")
    print(f"  Simple:  {bind_simple*100:4.1f}%")
    print(f"  Ambig:   {bind_amb*100:4.1f}%")
    print(f"\nMean attention mass on correct candidate(s): {mass_mean*100:4.1f}%")

    # Probe diagnostics
    ctm.eval()
    probe_color_correct = 0
    probe_shape_correct = 0
    probe_total = 0
    pos_mse_sum = 0.0
    pos_count = 0
    with torch.no_grad():
        for x, y, amb, cand_mask, obj_colors, obj_shapes, obj_pos in eval_loader:
            x = x.to(device)
            obj_colors = obj_colors.to(device)
            obj_shapes = obj_shapes.to(device)
            obj_pos = obj_pos.to(device)

            _, _, _, _, slots = ctm(x, return_attn=False, return_slots=True)
            B, N, D = slots.shape
            slots_flat = slots.reshape(B * N, D)
            colors_flat = obj_colors.view(B * N)
            shapes_flat = obj_shapes.view(B * N)
            pos_flat = obj_pos.view(B * N, 2)

            color_logits = ctm.probe_color(slots_flat)
            shape_logits = ctm.probe_shape(slots_flat)
            pos_pred = ctm.probe_pos(slots_flat)

            color_pred = color_logits.argmax(dim=-1)
            shape_pred = shape_logits.argmax(dim=-1)

            probe_color_correct += (color_pred == colors_flat).sum().item()
            probe_shape_correct += (shape_pred == shapes_flat).sum().item()
            probe_total += colors_flat.numel()

            pos_mse_sum += F.mse_loss(pos_pred, pos_flat, reduction="sum").item()
            pos_count += pos_flat.numel()

    probe_color_acc = probe_color_correct / max(1, probe_total)
    probe_shape_acc = probe_shape_correct / max(1, probe_total)
    probe_pos_mse = pos_mse_sum / max(1, pos_count)

    print("\nPROBE METRICS (Slots → object attributes):")
    print(f"  Color accuracy: {probe_color_acc*100:4.1f}%")
    print(f"  Shape accuracy: {probe_shape_acc*100:4.1f}%")
    print(f"  Position MSE:   {probe_pos_mse:.4f}")

    print("\n" + "=" * 60)
    print("v1.2 HARD BINDING COMPLETE")
    print("=" * 60)


# ---------------------------------------------------------------------
# SIMPLE GRIDWORLD
# ---------------------------------------------------------------------

class GridWorld:
    """
    Simple 2D grid world with a single agent and a fixed goal.

    - Grid size: cfg.gw_size x cfg.gw_size
    - State: one-hot agent position + one-hot goal position.
    - Actions: 0=up, 1=down, 2=left, 3=right.
    - Reward: +1.0 on reaching goal, -0.01 per step otherwise.
    """

    def __init__(self, size: int = 5):
        self.size = size
        self.n_actions = 4
        self.obs_dim = size * size * 2
        self.reset()

    def reset(self) -> torch.Tensor:
        self.agent_pos = [0, 0]
        self.goal_pos = [self.size - 1, self.size - 1]
        return self._get_obs()

    def _get_obs(self) -> torch.Tensor:
        agent_oh = torch.zeros(self.size * self.size)
        goal_oh = torch.zeros(self.size * self.size)
        agent_idx = self.agent_pos[0] * self.size + self.agent_pos[1]
        goal_idx = self.goal_pos[0] * self.size + self.goal_pos[1]
        agent_oh[agent_idx] = 1.0
        goal_oh[goal_idx] = 1.0
        return torch.cat([agent_oh, goal_oh], dim=0)

    def step(self, action: int) -> Tuple[torch.Tensor, float, bool]:
        if action == 0:   # up
            self.agent_pos[0] = max(0, self.agent_pos[0] - 1)
        elif action == 1:  # down
            self.agent_pos[0] = min(self.size - 1, self.agent_pos[0] + 1)
        elif action == 2:  # left
            self.agent_pos[1] = max(0, self.agent_pos[1] - 1)
        elif action == 3:  # right
            self.agent_pos[1] = min(self.size - 1, self.agent_pos[1] + 1)

        reward = -0.01
        done = False
        if self.agent_pos == self.goal_pos:
            reward = 1.0
            done = True

        return self._get_obs(), reward, done


# ---------------------------------------------------------------------
# ETERNAL HYPERGRAPH (minimal)
# ---------------------------------------------------------------------

class NodeType(Enum):
    EXPERIENCE = "experience"
    GOAL = "goal"


@dataclass
class HyperNode:
    id: str
    node_type: NodeType
    embedding: torch.Tensor  # [D] on CPU
    data: Dict[str, Any]
    reward: float = 0.0
    created_at: int = 0


class EternalHypergraph:
    """
    Tiny experience-based world model:
    - Stores (z_t, a, z_{t+1}, r) as EXPERIENCE nodes.
    - Supports simple similarity-based retrieval over embeddings.
    - Tracks a global step counter.
    """

    def __init__(self, embedding_dim: int, max_nodes: int = 5000):
        self.embedding_dim = embedding_dim
        self.max_nodes = max_nodes
        self.nodes: Dict[str, HyperNode] = {}
        self.experience_ids: List[str] = []
        self.step = 0

    def add_experience(self, z: torch.Tensor, action: int,
                       z_next: torch.Tensor, reward: float) -> str:
        self.step += 1
        node_id = f"exp_{len(self.nodes)}_{self.step}"
        emb = z.detach().cpu().clone()
        node = HyperNode(
            id=node_id,
            node_type=NodeType.EXPERIENCE,
            embedding=emb,
            data={
                "z_next": z_next.detach().cpu().clone(),
                "action": int(action),
                "reward": float(reward),
            },
            reward=float(reward),
            created_at=self.step,
        )
        self.nodes[node_id] = node
        self.experience_ids.append(node_id)
        if len(self.experience_ids) > self.max_nodes:
            old_id = self.experience_ids.pop(0)
            self.nodes.pop(old_id, None)
        return node_id

    def retrieve_similar(self, z: torch.Tensor, k: int = 16) -> List[HyperNode]:
        if not self.experience_ids:
            return []
        ids = list(self.experience_ids)
        embs = torch.stack([self.nodes[i].embedding for i in ids], dim=0).to(z.device)
        z_norm = F.normalize(z.unsqueeze(0), dim=-1)
        embs_norm = F.normalize(embs, dim=-1)
        sims = torch.matmul(embs_norm, z_norm.transpose(0, 1)).squeeze(-1)
        topk = torch.topk(sims, k=min(k, sims.numel()))
        return [self.nodes[ids[idx]] for idx in topk.indices.tolist()]

    def get_action_values(self, z: torch.Tensor, n_actions: int) -> torch.Tensor:
        if not self.experience_ids:
            return torch.zeros(n_actions, device=z.device)
        ids = list(self.experience_ids)
        embs = torch.stack([self.nodes[i].embedding for i in ids], dim=0).to(z.device)
        z_norm = F.normalize(z.unsqueeze(0), dim=-1)
        embs_norm = F.normalize(embs, dim=-1)
        sims = torch.matmul(embs_norm, z_norm.transpose(0, 1)).squeeze(-1)  # [N]
        q_vals = torch.zeros(n_actions, device=z.device)
        counts = torch.zeros(n_actions, device=z.device) + 1e-6
        for sim, node in zip(sims, [self.nodes[i] for i in ids]):
            a = node.data.get("action", 0)
            if 0 <= a < n_actions:
                q_vals[a] += sim * node.data.get("reward", 0.0)
                counts[a] += sim.abs()
        return q_vals / counts


# ---------------------------------------------------------------------
# ACTIVE INFERENCE AGENT (minimal)
# ---------------------------------------------------------------------

class ActiveInferenceAgent(nn.Module):
    """
    Lightweight Active Inference agent:
    - Latent belief z comes from an encoder (here CTMBlock).
    - Has a small neural transition model f(z, a).
    - Uses EternalHypergraph as a memory-based world model.
    - Selects actions via a simple score combining memory-based Q.
    """

    def __init__(self, latent_dim: int, n_actions: int):
        super().__init__()
        self.latent_dim = latent_dim
        self.n_actions = n_actions

        self.transition = nn.Sequential(
            nn.Linear(latent_dim + n_actions, latent_dim),
            nn.ReLU(),
            nn.Linear(latent_dim, latent_dim),
        )

        # Learnable weights for combining neural vs memory predictions
        self.w_reward = nn.Parameter(torch.tensor(1.0))
        self.w_memory = nn.Parameter(torch.tensor(0.5))

    def forward_transition(self, z: torch.Tensor, action: int) -> torch.Tensor:
        a_onehot = torch.zeros(self.n_actions, device=z.device)
        a_onehot[action] = 1.0
        inp = torch.cat([z, a_onehot], dim=-1)
        return self.transition(inp)

    def select_action(self, z: torch.Tensor,
                      hypergraph: EternalHypergraph,
                      temperature: float = 1.0,
                      deterministic: bool = False) -> Tuple[int, Dict[str, Any]]:
        memory_q = hypergraph.get_action_values(z.detach(), self.n_actions)
        scores = []
        for a in range(self.n_actions):
            score = self.w_reward * 0.0 + self.w_memory * memory_q[a]
            scores.append(score)
        scores_t = torch.stack(scores)
        if deterministic:
            action = int(scores_t.argmax().item())
            probs = torch.zeros_like(scores_t)
            probs[action] = 1.0
        else:
            probs = torch.softmax(scores_t / temperature, dim=-1)
            action = int(torch.multinomial(probs, 1).item())
        return action, {
            "scores": scores_t.detach().cpu(),
            "probs": probs.detach().cpu(),
            "q_memory": memory_q.detach().cpu(),
        }


# ---------------------------------------------------------------------
# USM agent for GridWorld
# ---------------------------------------------------------------------

class USMGridWorldAgent(nn.Module):
    """
    USM agent for GridWorld:
    - Encodes observations to latent z via MLP + CTMBlock.
    - Uses ActiveInferenceAgent with EternalHypergraph memories.
    - Has a Q head trained with TD(0).
    """

    def __init__(self, obs_dim: int, latent_dim: int, n_actions: int):
        super().__init__()
        self.obs_enc = nn.Sequential(
            nn.Linear(obs_dim, latent_dim),
            nn.ReLU(),
            nn.Linear(latent_dim, latent_dim),
        )
        self.ctm = CTMBlock(dim=latent_dim, n_slots=1, n_ticks=1)
        self.active = ActiveInferenceAgent(latent_dim, n_actions)
        self.q_head = nn.Linear(latent_dim, n_actions)

    def encode_latent(self, obs: torch.Tensor) -> torch.Tensor:
        z0 = self.obs_enc(obs.unsqueeze(0))   # [1,D]
        z_seq = z0.unsqueeze(1)               # [1,1,D]
        z_out, _, _, _ = self.ctm(z_seq, return_attn=False)
        return z_out.squeeze(1).squeeze(0)

    def act(self, z: torch.Tensor, hypergraph: EternalHypergraph,
            temperature: float = 1.0, deterministic: bool = False) -> Tuple[int, Dict[str, Any]]:
        return self.active.select_action(z, hypergraph, temperature, deterministic)


# ---------------------------------------------------------------------
# GRIDWORLD EXPERIMENT
# ---------------------------------------------------------------------

def run_gridworld_experiment(cfg: USMConfig):
    global device
    device = resolve_device(cfg)
    torch.manual_seed(cfg.seed)
    random.seed(cfg.seed)

    print("=" * 60)
    print("USM v1.1: GRIDWORLD + HYPERGRAPH + ACTIVE INFERENCE")
    print("=" * 60)
    print("Device:", device)

    env = GridWorld(size=cfg.gw_size)
    agent = USMGridWorldAgent(env.obs_dim, cfg.gw_latent_dim, env.n_actions).to(device)
    hypergraph = EternalHypergraph(embedding_dim=cfg.gw_latent_dim)
    optimizer = torch.optim.Adam(agent.parameters(), lr=cfg.gw_lr)
    gamma = cfg.gw_gamma

    def tensorize(obs: torch.Tensor) -> torch.Tensor:
        return obs.to(device).float()

    reward_history = []
    success_history = []

    for ep in range(1, cfg.gw_n_episodes + 1):
        obs = env.reset()
        total_r = 0.0
        success = False
        for step in range(cfg.gw_max_steps):
            obs_t = tensorize(obs)
            z = agent.encode_latent(obs_t)
            action, info = agent.act(z, hypergraph, temperature=1.0)
            next_obs, reward, done = env.step(action)
            total_r += reward
            if done and reward > 0:
                success = True

            next_obs_t = tensorize(next_obs)
            z_next = agent.encode_latent(next_obs_t)

            # Memory insertion
            hypergraph.add_experience(z, action, z_next, reward)

            # TD(0) update on Q head
            q_pred = agent.q_head(z)
            q_val = q_pred[action]
            with torch.no_grad():
                q_next = agent.q_head(z_next)
                target = reward + (0.0 if done else gamma * q_next.max().item())
            loss_td = F.mse_loss(q_val, torch.tensor(target, device=device))

            optimizer.zero_grad()
            loss_td.backward()
            optimizer.step()

            obs = next_obs
            if done:
                break

        reward_history.append(total_r)
        success_history.append(1.0 if success else 0.0)

        if ep % 20 == 0 or ep == cfg.gw_n_episodes:
            span = min(20, len(reward_history))
            avg_r = sum(reward_history[-span:]) / span
            avg_succ = sum(success_history[-span:]) / span
            print(f"Episode {ep:3d} | avg_reward(last{span})={avg_r:.3f} "
                  f"| success_rate(last{span})={avg_succ*100:4.1f}% "
                  f"| mem_size={len(hypergraph.experience_ids)}")

    print("\n" + "=" * 60)
    print("GRIDWORLD TRAINING COMPLETE")
    print("=" * 60)


# ---------------------------------------------------------------------
# ENTRY POINT
# ---------------------------------------------------------------------

def main():
    cfg = USMConfig()
    if cfg.world_type == "hard_binding":
        run_hard_binding_experiment(cfg)
    elif cfg.world_type == "gridworld":
        run_gridworld_experiment(cfg)
    else:
        raise ValueError(f"Unknown world_type: {cfg.world_type}")


if __name__ == "__main__":
    main()